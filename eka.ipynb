{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f229fbc4",
   "metadata": {},
   "source": [
    "## Ensimmäinen harjoitustehtävä - Ville Kurikka\n",
    "\n",
    "Aloitetaan lataamalla tarvittavat importit. Osa pip-installilla, koska uusi environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9b9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c65c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637368c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'ID': 191, 'type': 'NATIVE', 'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'venue': 'Significance, 2021', 'year': 2021, 'journal': 'Significance, 2021', 'DOI': '1740-9713.01589', 'URL': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
      "           name     role         type demographic  \\\n",
      "0  sepal length  Feature   Continuous        None   \n",
      "1   sepal width  Feature   Continuous        None   \n",
      "2  petal length  Feature   Continuous        None   \n",
      "3   petal width  Feature   Continuous        None   \n",
      "4         class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                               None    cm             no  \n",
      "1                                               None    cm             no  \n",
      "2                                               None    cm             no  \n",
      "3                                               None    cm             no  \n",
      "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n",
      "class    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "import pandas as pd\n",
    "  \n",
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = iris.data.features \n",
    "y = iris.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(iris.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(iris.variables) \n",
    "\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9ed9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b84241",
   "metadata": {},
   "source": [
    "Muutetaan aluksi target labelit numeroiksi, ja tämän jälkeen categorical-dataksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca017990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kurik\\anaconda3\\envs\\neurot\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = to_categorical(y, 3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b3449f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d39f0d",
   "metadata": {},
   "source": [
    "Data näyttää oikeanmuotoiselta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a9cae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length    float64\n",
      "sepal width     float64\n",
      "petal length    float64\n",
      "petal width     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a70117",
   "metadata": {},
   "source": [
    "X-dataframessa voidaan hyödyntää float-arvoja, mutta skaalataan standardscalerilla. Tämä vaikutti parantavan tarkkuutta noin neljällä prosenttiyksiköllä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d97af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70339469",
   "metadata": {},
   "source": [
    "Aloitetaan mallin rakennus. Alla siis 1 inputlayer, jossa 4 muuttujaa. Flattenia ei tarvita, koska 1d-dataa jo valmiiksi. Seuraavaksi 1 hidden layer, jossa 16 neuronia. Lopuksi vielä output-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "478b50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(4, )),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233637fe",
   "metadata": {},
   "source": [
    "Hyödynnetään mallin rakennuksessa Adam-optimizeria. Muutetaan learning rate 0.001:stä 0.01:teen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10573564",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995fc2f0",
   "metadata": {},
   "source": [
    "Koulutetaan malli. Epookkeja 6 kpl, ja jokaisella kerralla jaetaan datasetti 5 batchiin. Jokaisesta batchista otetaan 20 % validointia varten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8783c9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6917 - loss: 1.1626 - val_accuracy: 0.0000e+00 - val_loss: 1.7338\n",
      "Epoch 2/6\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.4729 - val_accuracy: 0.0000e+00 - val_loss: 0.9569\n",
      "Epoch 3/6\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.3572 - val_accuracy: 0.7333 - val_loss: 0.6209\n",
      "Epoch 4/6\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.3085 - val_accuracy: 0.0000e+00 - val_loss: 1.3272\n",
      "Epoch 5/6\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9083 - loss: 0.2771 - val_accuracy: 1.0000 - val_loss: 0.4653\n",
      "Epoch 6/6\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.2413 - val_accuracy: 1.0000 - val_loss: 0.4325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b2598545d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=6, batch_size=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a546ce38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.2814  \n",
      "0.9866666793823242\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X, y)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d935021",
   "metadata": {},
   "source": [
    "Mallin tarkkuus on n. 98,7 prosenttia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efacac03",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
